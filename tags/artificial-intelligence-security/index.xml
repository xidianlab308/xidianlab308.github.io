<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Artificial Intelligence Security - 标签 - 西电EIII308西网络安全创新开放实验室</title><link>https://xidianlab308.github.io/tags/artificial-intelligence-security/</link><description>Artificial Intelligence Security - 标签 - 西电EIII308西网络安全创新开放实验室</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Thu, 12 May 2022 09:40:28 +0800</lastBuildDate><atom:link href="https://xidianlab308.github.io/tags/artificial-intelligence-security/" rel="self" type="application/rss+xml"/><item><title>人工智能安全</title><link>https://xidianlab308.github.io/posts/artificial-intelligence-security/</link><pubDate>Thu, 12 May 2022 09:40:28 +0800</pubDate><author>作者</author><guid>https://xidianlab308.github.io/posts/artificial-intelligence-security/</guid><description>&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;p>The past several years have witnessed the rapid development of Deep Learning technology. Various DL models today are widely adopted in many scenarios, e.g., image classification, speech recognition, language processing, robotics control. These applications significantly enhance the quality of life. However, new security threats are introduced to DNN models including backdoor attacks, adversarial attacks, model extraction attacks, privacy inference attacks, etc. It is critical to protect these DNN models against existing or potential integrity and privacy attacks, especially in safety-critical fields such as autonomous driving and smart medical care. Our team aims to promote the academic research and industrial practice of artificial intelligence security, and explore new theories, new methods and new techniques for artificial intelligence security and privacy protection.&lt;/p></description></item></channel></rss>